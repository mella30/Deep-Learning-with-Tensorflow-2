{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Kopie von Coding Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Zo5rD5ZcJDK_",
        "NrE0rpCVJDL1",
        "yrX43gwPJDL-",
        "MHcNqGnWJDMH",
        "9Ti4kMquJDML",
        "jR7y1e-xJDMd",
        "H3srEhqCJDM7"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mella30/Deep-Learning-with-Tensorflow-2/blob/main/Course2-Customising_your_models_with_Tensorflow_2/week3_sequence_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk88Aw4NJDIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29baa0aa-a9a0-48b5-af96-655812eaff1d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "GPU name: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz2EbG1zvZx8"
      },
      "source": [
        "# imports for convenience\n",
        "from tensorflow.keras.layers import Embedding, Masking, GlobalAveragePooling1D, Dense, Input\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb8nVqLJDI5"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### 1.  The IMDb dataset\n",
        " #### 2. Padding and masking sequence data\n",
        " #### 3. The `Embedding` layer\n",
        " #### 4. The Embedding Projector\n",
        " #### 5. Recurrent neural network layers\n",
        " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3PNw3gJDI7"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqGZQ8WJDJF"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_c1LL5JDJG"
      },
      "source": [
        "# Import imdb\n",
        "\n",
        "import tensorflow.keras.datasets.imdb as imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jYJCwXJDJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f936ff3-2a4d-40b8-d667-7b02429879d8"
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oCnB8UMJDJP"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RwIt-pJDJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53542b25-dbbf-4f0f-eea8-4ffcc0a983b2"
      },
      "source": [
        "# Inspect the type of the data\n",
        "\n",
        "type(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viryy_PDJDJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac1989b-ad00-4d3c-b2e8-dd14647212c9"
      },
      "source": [
        "# Inspect the shape of the data\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6E6v-FJDJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed58a362-1ade-413e-ef07-729b2ac9edc3"
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbEqyjxJDJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8afeeb-29c4-44f5-dac6-795b511c5ef3"
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAk-PyOgJDJg"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzFxDj-JDJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ffe877-a0bc-4a43-9917-1185c2614959"
      },
      "source": [
        "# Load the dataset with defaults\n",
        "imdb.load_data(path='imdb.npz',\n",
        "               index_from=3)\n",
        "\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGfzZg3JDJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80853c67-daac-4eef-e1e6-62276df63b76"
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "imdb.load_data(num_words=1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
              "         list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 2, 5, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 950, 5, 2, 15, 45, 629, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2, 7, 2, 861, 2, 5, 2, 30, 2, 2, 56, 4, 841, 5, 990, 692, 8, 4, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 565, 921, 2, 39, 4, 529, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 2]),\n",
              "         list([1, 111, 748, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 748, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 2, 2, 2, 2, 8, 847, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 993, 2, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 655, 2, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 2, 18, 631, 2, 797, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 656, 6, 2, 54, 2, 2, 98, 6, 2, 40, 558, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 711, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 930, 8, 508, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 584, 10, 10, 2, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 7, 819, 4, 22, 2, 17, 6, 2, 787, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 704, 7, 101, 999, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 910, 769, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 743, 46, 2, 9, 2, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 6, 2, 7, 470]),\n",
              "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 519, 2, 6, 769, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 718, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkXgUGaJDJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e782abc8-8fbf-4fd3-bce4-87ed16bffe9e"
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "\n",
        "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
              "         ...,\n",
              "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
              "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
              "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
              "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
              "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
              "         ...,\n",
              "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
              "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
              "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDAFt0FJDJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aceb227c-834d-4a6a-a92d-89a704c5f3f4"
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "\n",
        "imdb.load_data(maxlen=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 13, 1228, 119, 14, 552, 7, 20, 190, 14, 58, 13, 258, 546, 1786, 8, 1968, 4, 268, 237, 13, 191, 81, 15, 13, 80, 43, 3824, 44, 12, 14, 16, 427, 3192, 4, 183, 15, 593, 19, 4, 351, 362, 26, 55, 646, 21, 4, 1239, 84, 26, 1557, 3755, 13, 244, 6, 2071, 132, 184, 194, 5, 13, 70, 4478, 546, 73, 190, 13, 62, 24, 81, 320, 4, 538, 4, 117, 250, 127, 11, 14, 20, 82, 4, 452, 11, 14, 20, 9, 8654, 19, 41, 476, 8, 4, 213, 7, 9185, 13, 657, 13, 286, 38, 1612, 44, 41, 5, 41, 1729, 88, 13, 62, 28, 900, 510, 4, 509, 51, 6, 612, 59, 16, 193, 61, 4666, 5, 702, 930, 143, 285, 25, 67, 41, 81, 366, 4, 130, 82, 9, 259, 334, 397, 1195, 7, 149, 102, 15, 26, 814, 38, 465, 1627, 31, 70, 983, 67, 51, 9, 112, 814, 17, 35, 311, 75, 26, 11649, 574, 19, 4, 1729, 23, 4, 268, 38, 95, 138, 4, 609, 191, 75, 28, 314, 1772]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 0, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RApLnw04lnZ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-Nr897LorW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6422a6-492b-4800-fd92-3f7f4a72b472"
      },
      "source": [
        " # Use '1' as the character that indicates the start of a sequence\n",
        "\n",
        " imdb.load_data(start_char=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBCKKGyJDJ7"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkaFf6MJDJ9"
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzgAIoKJDKB"
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "\n",
        "index_from = 3\n",
        "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCi_QIzJDKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3f12d5-b790-4d37-ceec-3e7533519150"
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "\n",
        "imdb_word_index['simpsonian']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_RrEQjHmfv6",
        "outputId": "5b2b633e-07c2-48de-be56-ce88c58703df"
      },
      "source": [
        "imdb_word_index['the']\n",
        "# most frequent word in the dataset -> frequency rank of 1 -> added to index from value (which equals 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UkZwHiJDKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3486dd0-0250-4e19-954c-6dc5e6f196f9"
      },
      "source": [
        "# View an input sentence\n",
        "\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'film',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'casting',\n",
              " 'location',\n",
              " 'scenery',\n",
              " 'story',\n",
              " 'direction',\n",
              " \"everyone's\",\n",
              " 'really',\n",
              " 'suited',\n",
              " 'the',\n",
              " 'part',\n",
              " 'they',\n",
              " 'played',\n",
              " 'and',\n",
              " 'you',\n",
              " 'could',\n",
              " 'just',\n",
              " 'imagine',\n",
              " 'being',\n",
              " 'there',\n",
              " 'robert',\n",
              " \"redford's\",\n",
              " 'is',\n",
              " 'an',\n",
              " 'amazing',\n",
              " 'actor',\n",
              " 'and',\n",
              " 'now',\n",
              " 'the',\n",
              " 'same',\n",
              " 'being',\n",
              " 'director',\n",
              " \"norman's\",\n",
              " 'father',\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'same',\n",
              " 'scottish',\n",
              " 'island',\n",
              " 'as',\n",
              " 'myself',\n",
              " 'so',\n",
              " 'i',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'real',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'witty',\n",
              " 'remarks',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'film',\n",
              " 'were',\n",
              " 'great',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'so',\n",
              " 'much',\n",
              " 'that',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'the',\n",
              " 'film',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'released',\n",
              " 'for',\n",
              " 'retail',\n",
              " 'and',\n",
              " 'would',\n",
              " 'recommend',\n",
              " 'it',\n",
              " 'to',\n",
              " 'everyone',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fly',\n",
              " 'fishing',\n",
              " 'was',\n",
              " 'amazing',\n",
              " 'really',\n",
              " 'cried',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'sad',\n",
              " 'and',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'they',\n",
              " 'say',\n",
              " 'if',\n",
              " 'you',\n",
              " 'cry',\n",
              " 'at',\n",
              " 'a',\n",
              " 'film',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'good',\n",
              " 'and',\n",
              " 'this',\n",
              " 'definitely',\n",
              " 'was',\n",
              " 'also',\n",
              " 'congratulations',\n",
              " 'to',\n",
              " 'the',\n",
              " 'two',\n",
              " 'little',\n",
              " \"boy's\",\n",
              " 'that',\n",
              " 'played',\n",
              " 'the',\n",
              " \"part's\",\n",
              " 'of',\n",
              " 'norman',\n",
              " 'and',\n",
              " 'paul',\n",
              " 'they',\n",
              " 'were',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'children',\n",
              " 'are',\n",
              " 'often',\n",
              " 'left',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'praising',\n",
              " 'list',\n",
              " 'i',\n",
              " 'think',\n",
              " 'because',\n",
              " 'the',\n",
              " 'stars',\n",
              " 'that',\n",
              " 'play',\n",
              " 'them',\n",
              " 'all',\n",
              " 'grown',\n",
              " 'up',\n",
              " 'are',\n",
              " 'such',\n",
              " 'a',\n",
              " 'big',\n",
              " 'profile',\n",
              " 'for',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'film',\n",
              " 'but',\n",
              " 'these',\n",
              " 'children',\n",
              " 'are',\n",
              " 'amazing',\n",
              " 'and',\n",
              " 'should',\n",
              " 'be',\n",
              " 'praised',\n",
              " 'for',\n",
              " 'what',\n",
              " 'they',\n",
              " 'have',\n",
              " 'done',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'story',\n",
              " 'was',\n",
              " 'so',\n",
              " 'lovely',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'true',\n",
              " 'and',\n",
              " 'was',\n",
              " \"someone's\",\n",
              " 'life',\n",
              " 'after',\n",
              " 'all',\n",
              " 'that',\n",
              " 'was',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2ID8wRJDKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc738ef-195a-43e4-d358-71b37a8faa66"
      },
      "source": [
        "# Get the sentiment value\n",
        "\n",
        "y_train[0]  # positive review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPUtmz-JDKZ"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UggNd-8VLgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5527c6-87a3-4a86-902d-89cfad827dd0"
      },
      "source": [
        "# Load the imdb data set\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqWhXi-JDKa"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWULtJ7CJDKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854cc10a-f218-4a81-dc26-f22c58d3d12d"
      },
      "source": [
        "# Inspect the input data shape\n",
        "\n",
        "x_train.shape  # resulting arrays are ragged (not all of the same length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOts_k01JDKh"
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen so that the array is not ragged anymore\n",
        "# sequences longer than maxlen will be truncated, sequences shorter than that will be padded\n",
        "\n",
        "padded_x_train = sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNPiMGwDJDKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2406dac7-ca87-4039-a18f-38a4040b87de"
      },
      "source": [
        "# Inspect the output data shape\n",
        "\n",
        "padded_x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt56letJDKn"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoMdifYJDKo"
      },
      "source": [
        "# Import numpy \n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LjX9QaJDKr"
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "\n",
        "padded_x_train = np.expand_dims(padded_x_train, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrgXbDrJDKt"
      },
      "source": [
        "# Create a Masking layer \n",
        "\n",
        "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
        "masking_layer = Masking(mask_value=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkSzdHwJDKw"
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "\n",
        "masked_x_train = masking_layer(tf_x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuStn9s0JDK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33044c1-dabb-49d5-f986-d976eaf3067e"
      },
      "source": [
        "# Look at the dataset\n",
        "\n",
        "tf_x_train\n",
        "masked_x_train\n",
        "# are both the same (added an additional property with mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
              "array([[[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [2.200e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.940e+02],\n",
              "        [1.153e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [4.700e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.100e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.446e+03],\n",
              "        [7.079e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.700e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54DVLx4JDK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065c3e1d-889d-453e-9438-2f227868bacb"
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n",
        "# tf_x_train._keras_mask  # does not have a mask property\n",
        "masked_x_train._keras_mask  # does have a mask property"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rD5ZcJDK_"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkBOM8mJDLA"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-esPcdDJDLJ"
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim (one bigger than largest index value) and output_dim (dimension of the embedding)\n",
        "\n",
        "embedding_layer = Embedding(input_dim=501, output_dim=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf3B6HamJDLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063ac14d-7540-4050-8215-0b14bd80e3f0"
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "\n",
        "sequence_of_indices = tf.constant([[[0], [1], [5], [500]]])\n",
        "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
        "sequence_of_embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
              "array([[[[-0.0182243 , -0.00735991,  0.04380231,  0.04286807,\n",
              "           0.04996133,  0.03869338,  0.03061661, -0.02717466,\n",
              "          -0.03630253,  0.01020597,  0.00892962, -0.01253889,\n",
              "          -0.017843  , -0.02355379, -0.04507774,  0.045419  ]],\n",
              "\n",
              "        [[-0.00607603,  0.00299356, -0.03402978,  0.00145004,\n",
              "          -0.02692659, -0.02889675, -0.02553393, -0.0216462 ,\n",
              "           0.00044053, -0.00535178,  0.02389259,  0.04897394,\n",
              "           0.04310616,  0.02953069,  0.0354155 ,  0.03754425]],\n",
              "\n",
              "        [[-0.02436736,  0.01727498, -0.04250383,  0.00748216,\n",
              "          -0.03074671,  0.02773461, -0.03582228,  0.04897596,\n",
              "           0.03292176, -0.0444057 , -0.00383844, -0.03770489,\n",
              "           0.00558449,  0.04174865, -0.01496377,  0.01571019]],\n",
              "\n",
              "        [[ 0.02899516,  0.02429273, -0.04325994,  0.03215786,\n",
              "          -0.02902563, -0.04380592, -0.02789925,  0.02947697,\n",
              "           0.02988489, -0.03626782, -0.02897727, -0.01165857,\n",
              "           0.02741842,  0.02822516, -0.03169079, -0.03971181]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualmsaPpJDLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff2870a-d571-46f5-ae5b-92c73c279367"
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "\n",
        "embedding_layer.get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0182243 , -0.00735991,  0.04380231, ..., -0.02355379,\n",
              "        -0.04507774,  0.045419  ],\n",
              "       [-0.00607603,  0.00299356, -0.03402978, ...,  0.02953069,\n",
              "         0.0354155 ,  0.03754425],\n",
              "       [ 0.03169451,  0.00111834, -0.01341008, ...,  0.01180194,\n",
              "         0.01158816, -0.00481756],\n",
              "       ...,\n",
              "       [-0.03398725, -0.04728656,  0.02352209, ...,  0.03281856,\n",
              "         0.02395344, -0.00173245],\n",
              "       [-0.02784332, -0.0457814 , -0.00435257, ..., -0.02464188,\n",
              "        -0.02836275, -0.0250921 ],\n",
              "       [ 0.02899516,  0.02429273, -0.04325994, ...,  0.02822516,\n",
              "        -0.03169079, -0.03971181]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wadlt3AJDLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b197895-17c9-4470-d8f7-10ea82583408"
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "\n",
        "embedding_layer.get_weights()[0][14,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00321324,  0.04833741,  0.00451167,  0.01898107,  0.03903976,\n",
              "        0.02327365,  0.00716344,  0.00734244, -0.01352536,  0.00155171,\n",
              "        0.02259201,  0.00428379, -0.01040666,  0.0049047 , -0.03408273,\n",
              "       -0.00486774], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuhReOm9xF7"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKYwKT_I-H2O"
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "\n",
        "masking_embedding_layer = Embedding(input_dim=501, output_dim=16, mask_zero=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hc1zx6A-H6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6befab-2225-404d-c421-781665d8fd9f"
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "\n",
        "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
        "masked_sequence_of_embeddings._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG6LF1MJDL0"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zna3TCoTAu00"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKYrlepAxPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b35108-dcfe-4ace-916a-c3796fb6b1b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAX9ENDBFFE"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5qBbDDBIdn"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = sequence.pad_sequences(x_train, \n",
        "                                     maxlen=None,\n",
        "                                     padding='pre',\n",
        "                                     truncating='pre',\n",
        "                                     value=0)\n",
        "    \n",
        "    x_test = sequence.pad_sequences(x_test,\n",
        "                                    maxlen=None,\n",
        "                                    padding='pre',\n",
        "                                    truncating='pre',\n",
        "                                    value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpymnb2BIiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed57a21e-cbd4-4bc1-dbd1-6da65858f1fe"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EtU2vK0BLts"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIEIdRBSxv"
      },
      "source": [
        "# Get the word index\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()  # encode a sentensce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2fp10YBS6T"
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}  # decode a sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquirCA8BS99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6a0462-f920-457f-ff72-16a109a6160a"
      },
      "source": [
        "# View the first dataset example sentence\n",
        "\n",
        "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'great',\n",
              " 'fan',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'and',\n",
              " 'have',\n",
              " 'everything',\n",
              " 'that',\n",
              " \"he's\",\n",
              " 'made',\n",
              " 'on',\n",
              " 'dvd',\n",
              " 'except',\n",
              " 'for',\n",
              " 'hotel',\n",
              " 'room',\n",
              " 'the',\n",
              " '2',\n",
              " 'hour',\n",
              " 'twin',\n",
              " 'peaks',\n",
              " 'movie',\n",
              " 'so',\n",
              " 'when',\n",
              " 'i',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'this',\n",
              " 'i',\n",
              " 'immediately',\n",
              " 'grabbed',\n",
              " 'it',\n",
              " 'and',\n",
              " 'and',\n",
              " 'what',\n",
              " 'is',\n",
              " 'this',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'drawn',\n",
              " 'black',\n",
              " 'and',\n",
              " 'white',\n",
              " 'cartoons',\n",
              " 'that',\n",
              " 'are',\n",
              " 'loud',\n",
              " 'and',\n",
              " 'foul',\n",
              " 'mouthed',\n",
              " 'and',\n",
              " 'unfunny',\n",
              " 'maybe',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " \"what's\",\n",
              " 'good',\n",
              " 'but',\n",
              " 'maybe',\n",
              " 'this',\n",
              " 'is',\n",
              " 'just',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'crap',\n",
              " 'that',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'public',\n",
              " 'under',\n",
              " 'the',\n",
              " 'name',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'few',\n",
              " 'bucks',\n",
              " 'too',\n",
              " 'let',\n",
              " 'me',\n",
              " 'make',\n",
              " 'it',\n",
              " 'clear',\n",
              " 'that',\n",
              " 'i',\n",
              " \"didn't\",\n",
              " 'care',\n",
              " 'about',\n",
              " 'the',\n",
              " 'foul',\n",
              " 'language',\n",
              " 'part',\n",
              " 'but',\n",
              " 'had',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'because',\n",
              " 'my',\n",
              " 'neighbors',\n",
              " 'might',\n",
              " 'have',\n",
              " 'all',\n",
              " 'in',\n",
              " 'all',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'highly',\n",
              " 'disappointing',\n",
              " 'release',\n",
              " 'and',\n",
              " 'may',\n",
              " 'well',\n",
              " 'have',\n",
              " 'just',\n",
              " 'been',\n",
              " 'left',\n",
              " 'in',\n",
              " 'the',\n",
              " 'box',\n",
              " 'set',\n",
              " 'as',\n",
              " 'a',\n",
              " 'curiosity',\n",
              " 'i',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'you',\n",
              " \"don't\",\n",
              " 'spend',\n",
              " 'your',\n",
              " 'money',\n",
              " 'on',\n",
              " 'this',\n",
              " '2',\n",
              " 'out',\n",
              " 'of',\n",
              " '10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrE0rpCVJDL1"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUfv9kjJDL1"
      },
      "source": [
        "# Get the maximum token value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO0CkecjJDL5"
      },
      "source": [
        "# Specify an embedding dimension\n",
        "\n",
        "embedding_dim = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBZOlp3JDL7"
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False),\n",
        "                             GlobalAveragePooling1D(),\n",
        "                             Dense(1, activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9qhtlPJDL9"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "review_sequence = Input((None, ))\n",
        "embedding_sequence = Embedding(input_dim=max_index_value+1, output_dim=embedding_dim)(review_sequence)\n",
        "average_embedding = GlobalAveragePooling1D()(embedding_sequence)\n",
        "positive_probability = Dense(1, activation='sigmoid')(average_embedding)\n",
        "\n",
        "model = tf.keras.Model(inputs=review_sequence, outputs=positive_probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf6oaEvTCKxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb899f6-8903-47ec-f668-74b6b9055a27"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrX43gwPJDL-"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfI_1EoJDL_"
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR-O7wGJDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1921657-b4a7-4d92-b99e-77d138085043"
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 10s 8ms/step - loss: 0.6903 - accuracy: 0.5756 - val_loss: 0.6843 - val_accuracy: 0.6016\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6743 - accuracy: 0.6666 - val_loss: 0.6572 - val_accuracy: 0.7437\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6367 - accuracy: 0.7458 - val_loss: 0.6112 - val_accuracy: 0.7281\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5873 - accuracy: 0.7871 - val_loss: 0.5625 - val_accuracy: 0.7812\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5385 - accuracy: 0.8112 - val_loss: 0.5207 - val_accuracy: 0.7969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ind0d_gvJDMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "1b613266-a788-4ae1-94d0-05a10ac64fdb"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcNqGnWJDMH"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVP4G9X0JDMH"
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n",
        "weights = model.layers[1].get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd29nfZJDMJ"
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open(path.join('/content/drive/MyDrive/data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "out_m = io.open(path.join('/content/drive/MyDrive/data', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in imdb_word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ti4kMquJDML"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hrm6Q2jJDMM"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7uSwkQJDMR"
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "# recurrent layers expect input shapes of (batch, sequence, features), where both batch and sequence shapes can be flexible (None)\n",
        "\n",
        "simplernn_layer = SimpleRNN(16)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YJUyrEJDMT",
        "outputId": "49a2d4e7-80df-44ad-ada6-2d1a3e4e12c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "\n",
        "example_sequence = tf.constant([[[1., 1.], [2., 2.], [65., -100.]]])\n",
        "layer_output = simplernn_layer(example_sequence)\n",
        "layer_output  # final state of the SimpleRNN layer"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[ 1.        ,  0.8902779 ,  1.        ,  1.        ,  1.        ,\n",
              "        -0.99970114, -1.        ,  0.99896663, -1.        , -0.9968428 ,\n",
              "        -1.        ,  1.        ,  1.        , -1.        ,  1.        ,\n",
              "        -0.99999774]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rwdZtmJDMV"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvAtycIpH1aA"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = sequence.pad_sequences(x_train,\n",
        "                                     maxlen=None,\n",
        "                                     padding='pre',\n",
        "                                     truncating='pre',\n",
        "                                     value=0)\n",
        "    \n",
        "    x_test = sequence.pad_sequences(x_test,\n",
        "                                    maxlen=None,\n",
        "                                    padding='pre',\n",
        "                                    truncating='pre',\n",
        "                                    value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rJuSFmJDMV",
        "outputId": "1bedb3e5-67c4-4b0f-ceb1-7c29500e4a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUHcFKwH4wh"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyqmfOXJDMX",
        "outputId": "e3fe4226-db1a-4964-f93e-aebfb9346e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7y1e-xJDMd"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym76m2dIVOZ"
      },
      "source": [
        "# Get the maximum index value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO953-oJDMd"
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
        "                             LSTM(16),\n",
        "                             Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v076l5CUJDMf"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRXW5mPJDMg"
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216PeHZFJDMi",
        "outputId": "da07b391-a93f-42eb-ca15-aa52d2a8fc43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit the model and save its training history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "536/536 [==============================] - 450s 830ms/step - loss: 0.4297 - accuracy: 0.7978\n",
            "Epoch 2/3\n",
            "536/536 [==============================] - 445s 829ms/step - loss: 0.2267 - accuracy: 0.9165\n",
            "Epoch 3/3\n",
            "536/536 [==============================] - 440s 820ms/step - loss: 0.1681 - accuracy: 0.9397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVXF1TSJDMj"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9VW07lJDMk"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAyEd6wJDMm"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9CHYLiJDMo"
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_test[] if index > 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf6in2dJDMs"
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "\n",
        "model.predict(x_test[None, 0, :])  # no batch, first review, entire sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCyKBsZHJDMt"
      },
      "source": [
        "# Get the corresponding label\n",
        "\n",
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpaI83PlJDMv"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr4kOevKRt8"
      },
      "source": [
        "#### Load and transform the IMDb review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06LdJiXKRt9"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjA8JlQVKRuB"
      },
      "source": [
        "# Load the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iBFGx9_KRuD"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lcV0UGKRuF"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_Vv9-5JDM1"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Sy-gMyLLEI"
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yWIAFdJDM1"
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-34ZWvRJDM3"
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpOIOCmJDM4"
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3srEhqCJDM7"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Dy_C6-JDM7"
      },
      "source": [
        "# Compile the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er8atiBoJDM9"
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLOLtBKwJDNA"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}