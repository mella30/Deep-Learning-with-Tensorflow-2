{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mella30/Deep-Learning-with-Tensorflow-2/blob/main/Course2-Customising_your_models_with_Tensorflow_2/week4_subclassing_custom_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Vdv9xfLUT9",
        "outputId": "0c453a71-fbca-407b-8c01-1bb30e456c3a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODTr_t4VLUUB"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpLf8goaLUUC"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkBUlKjaLUUE"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Btd3AmLUUF"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufaa6AMZLUUF"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmKcYHEoLUUG"
      },
      "source": [
        "# Build the model\n",
        "# One branch has only the dense one layer, the other has the dense two, a dense three layers sequentially.\n",
        "# Then the outputs of both branches can be concatenated by just writing concatenate. \n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.dense_1 = Dense(64, activation='relu')\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dense_3 = Dense(5)\n",
        "    self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs, training=True):\n",
        "    x = self.dense_1(inputs)\n",
        "    y1 = self.dense_2(inputs)\n",
        "    y2 = self.dense_3(y1)\n",
        "    concat = concatenate([x,y2])\n",
        "    return self.softmax(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLJ57PmfLUUG",
        "outputId": "888ed13a-261c-4d82-fe35-6f21cb1862c9"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8w1peLbLUUH"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5jndnizLUUI"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aSbZBB7LUUJ"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBPsloJ5LUUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36ef519-715b-4cd8-a413-4c36af75133f"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units),\n",
        "                             initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer='zeros')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.03462956  0.27807447 -0.0415416 ]], shape=(1, 3), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.05272692,  0.07202636,  0.07036196],\n",
            "       [-0.01977646,  0.14034642,  0.03701119],\n",
            "       [-0.04026626, -0.04271299, -0.1432971 ],\n",
            "       [-0.07335179,  0.08981531, -0.00660157],\n",
            "       [ 0.04603803,  0.01859936,  0.00098393]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2tENUI8LUUL"
      },
      "source": [
        "# Specify trainable weights (to freeze parts of the layers weights) \n",
        "\n",
        "class MyLayerNontrainable(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayerNontrainable, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units),\n",
        "                             initializer='random_normal',\n",
        "                             trainable=False)\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer='zeros',\n",
        "                             trainable=False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "dense_layer_nontrainable = MyLayerNontrainable(3,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GGVI6adLUUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f0221f-2bbe-47ba-82fb-080bde683075"
      },
      "source": [
        "print('trainable weights:', len(dense_layer_nontrainable.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer_nontrainable.non_trainable_weights))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iw7rdoRLUUM"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "# \n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayerMean, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units),\n",
        "                             initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer='zeros')\n",
        "    # accumulate means of output values everytime it is called\n",
        "    self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                      trainable=False)\n",
        "    # counts the number of times the layer has been called\n",
        "    self.number_call = tf.Variable(initial_value=0,\n",
        "                                   trainable=False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    # activation of the outputs\n",
        "    activations = tf.matmul(inputs, self.w)+self.b\n",
        "    # update values (sum and number of calls, will keep their values across calls) \n",
        "    self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "    self.number_call.assign_add(inputs.shape[0])\n",
        "    return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer_mean = MyLayerMean(3,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGc_DJeTLUUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b119fd67-2ce9-4b4f-c077-77c40fa3991a"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer_mean(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "\n",
        "# nothing changes because weights and bias are not updated\n",
        "y, activation_means = dense_layer_mean(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "# Accumulating the mean or variance of the activations can be really useful e.g. for analyzing the propagation of signals in the network. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05410447 0.08467079 0.06959186]\n",
            "[0.05410447 0.08467079 0.06959186]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74unDX1sLUUM"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeJQLlOaLUUN"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBNDA6QgLUUN"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)  # call activations here, otherwise the layers will be linear\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        return self.softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uszswhk-RWUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f827c8-925f-4100-aca9-6322e5149b47"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.05454328 0.03436927 0.01711915 0.00422174 0.01680824 0.01881411\n",
            "  0.00889291 0.02258453 0.00444886 0.00678244 0.00503646 0.01405701\n",
            "  0.01003517 0.00785683 0.008182   0.01316038 0.02942613 0.07519828\n",
            "  0.013987   0.00851373 0.03548283 0.00565946 0.00386675 0.01540067\n",
            "  0.00643616 0.00304706 0.00739376 0.00267    0.01084765 0.04675708\n",
            "  0.00984404 0.02394733 0.00348202 0.0373905  0.00611185 0.00754119\n",
            "  0.07485764 0.0198659  0.02637891 0.02605296 0.06726679 0.00403698\n",
            "  0.02178637 0.01637157 0.09099672 0.05247034]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_1 (MyLayer)         multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout (MyDropout)       multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_2 (MyLayer)         multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_1 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_3 (MyLayer)         multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqD_K6AjLUUO"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjyrD5WmLUUO"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stiepnYlLUUP"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ_qrLpBLUUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "48471e8e-3d51-4226-d65b-c139b9c950a0"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f06f11bf790>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQzElEQVR4nO3dfYzlV13H8feHdguaLtS0A8HtLguBqgSFhVFomkihCm2NNEYUVCqQ4qaIhMb+UVMiGvijIWgRwkPdUIViFZCuuEFRK3Stxe3q7rJ0210hlYdS2NgpD22VQFn69Y97V6azM3vvdH/36cz7lUzmzr1n7v2ezvSzZ84953dSVUiSZt+jJl2AJKkbBrokNcJAl6RGGOiS1AgDXZIacfKkXviMM86ozZs3T+rlJWkm7d27996qmlvusYkF+ubNm9mzZ8+kXl6SZlKSL6/0mFMuktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiSN0a5dcNVVvc9dG7gOPcljgJuBR/fbf7Sq/mBJm0cD1wHPAb4OvKyqvtR5tZI0w3btgvPOgwcfhFNOgU9+Es4+u7vnH2aE/l3ghVX1TOBZwPlJnrekzSXAN6vqqcDbgbd2V6IktWHnzl6Yf//7vc87d3b7/AMDvXr+p//luv7H0lMxLgI+0L/9UeC8JOmsSklqwLnn9kbmJ53U+3zuud0+/1Bb/5OcBOwFngq8u6p2L2myAfgKQFUdSXIfcDpw75Ln2QpsBdi0adOJVS5JM+bss3vTLDt39sK8y+kWGDLQq+r7wLOSnAb8TZJnVNXtq32xqtoGbAOYn5/37DtJa87ZZ3cf5EetapVLVX0LuAk4f8lDXwU2AiQ5GXgcvTdHJUljMjDQk8z1R+Yk+SHg54H/XNJsB/DK/u2XAp8qT5+WpLEaZsrlicAH+vPojwI+UlUfT/JmYE9V7QCuBT6Y5E7gG8DLR1axJGlZAwO9qm4Dtixz/5sW3f4O8CvdliZJWg13ikpSIwx0SWqEgS5JjTDQJWlERnkhruVM7JBoSWrZqC/EtRxH6JI0AqO+ENdyDHRJGoFRX4hrOU65SNIIjPpCXMsx0CVpREZ5Ia7lOOUiSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXNPPGfZDEtPLiXJJm2iQOkphWjtAlzbRJHCQxrQx0STNtEgdJTCunXCT9v127xnsgQxcmcZDEtDLQJQGzPRc97oMkppVTLpIA56JbYKBLApyLboFTLpIA56JbMDDQk2wErgOeABSwraresaTN44C/ADb1n/OPqurPuy9X0ig5Fz3bhhmhHwEur6p9SdYDe5PcWFUHF7V5HXCwqn4xyRzwuSTXV9WDoyhaknSsgXPoVXW4qvb1bz8AHAI2LG0GrE8S4FTgG/T+IZC0Rrkdf/xWNYeeZDOwBdi95KF3ATuArwHrgZdV1UPLfP9WYCvApk2bVl+tpJkwy0sgZ9nQq1ySnArcAFxWVfcvefjFwH7gR4FnAe9K8tilz1FV26pqvqrm5+bmTqBsSdPMJZCTMVSgJ1lHL8yvr6rtyzR5NbC9eu4Evgj8eHdlSpolLoGcjGFWuQS4FjhUVVev0Owu4DzgX5M8Afgx4AudVSlppixeAnn66T8YoTvtMlrDzKGfA1wMHEiyv3/flfSWKFJV1wBvAd6f5AAQ4IqquncE9UqaEUfD27n08RkY6FV1C72QPl6brwEv6qooSW1Ybi7dQB8dt/5LGhnn0sfLrf+SRsbLCYyXgS5ppLycwPg45SJJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWNhUfSjZ5b/yWNnEfSjYcjdEkj55F042GgSx1xSmFlXkZ3PJxykTrglMLxeRnd8TDQpQ54Ms9gXkZ39JxykTrglIKmgSN0qQNOKWgaGOhSR5xS0KQ55SJJjTDQpTXEpZVtc8pFWiNcWtk+R+jSGuFuzfYZ6NIa4dLK9jnlIq0RLq1sn4EurSEurWybUy6S1IiBgZ5kY5KbkhxMckeSN6zQ7twk+/tt/qX7UiVJxzPMlMsR4PKq2pdkPbA3yY1VdfBogySnAe8Bzq+qu5I8fkT1SpJWMHCEXlWHq2pf//YDwCFgw5Jmvw5sr6q7+u3u6bpQSdPBzUnTa1VviibZDGwBdi956CxgXZKdwHrgHVV1XQf1SZoibk6abkO/KZrkVOAG4LKqun/JwycDzwF+AXgx8PtJzlrmObYm2ZNkz8LCwgmULWkS3Jw03YYK9CTr6IX59VW1fZkmdwP/WFX/W1X3AjcDz1zaqKq2VdV8Vc3Pzc2dSN2SJsDNSdNt4JRLkgDXAoeq6uoVmv0t8K4kJwOnAM8F3t5ZlZKmgpuTptswc+jnABcDB5Ls7993JbAJoKquqapDSf4BuA14CHhfVd0+ioIlTZabk6bXwECvqluADNHubcDbuihKkrR67hSVpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0KUR8CBlTcKqDomWNJgHKWtSHKFLHfMgZU2KgS51zIOUNSlOuUgd8yBlTYqBLo2ABylrEpxykaRGGOiS1AgDXZIaYaBrotyAI3XHN0U1MW7AkbrlCF0T4wYcqVsGuibGDThSt5xy0cS4AUfqloGuiXIDjtQdp1wkqREDAz3JxiQ3JTmY5I4kbzhO259OciTJS7stU5I0yDBTLkeAy6tqX5L1wN4kN1bVwcWNkpwEvBX4pxHUKUkaYOAIvaoOV9W+/u0HgEPAhmWavh64Abin0wolSUNZ1Rx6ks3AFmD3kvs3AL8EvHfA929NsifJnoWFhdVVKkk6rqEDPcmp9Ebgl1XV/Use/hPgiqp66HjPUVXbqmq+qubn5uZWX60kaUVDLVtMso5emF9fVduXaTIPfCgJwBnAhUmOVNXHOqtUa9quXa5XlwYZGOjppfS1wKGqunq5NlX15EXt3w983DBXV7zmizScYaZczgEuBl6YZH//48Iklya5dMT1SV7zRRrSwBF6Vd0CZNgnrKpXnUhB0lJHr/lydITuNV+k5bn1X1PPa75IwzHQNRO85os0mNdykaRGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBPma7dsFVV/U+S1KXvHzuGHmUmqRRcoQ+Rh6lJmmUDPQxOnqU2kkneZSapO455TJGHqUmaZQM9DHzKDVJo+KUiyQ1wkCXpEYY6JLUCANdM8tNWtLD+aaoOrFr13hX77hJSzqWga4TNolwXW6TloGutc4pF52wSeyAdZOWdCxH6DphR8P16Ah9HOHqJi3pWAMDPclG4DrgCUAB26rqHUva/AZwBRDgAeC1VfXZ7svVNJpUuLpJS3q4YUboR4DLq2pfkvXA3iQ3VtXBRW2+CDy/qr6Z5AJgG/DcEdSrKWW4SpM3MNCr6jBwuH/7gSSHgA3AwUVt/m3Rt9wKnNlxnZKkAVb1pmiSzcAWYPdxml0CfGKF79+aZE+SPQsLC6t5aUnSAEMHepJTgRuAy6rq/hXavIBeoF+x3ONVta2q5qtqfm5u7pHUK0lawVCrXJKsoxfm11fV9hXa/BTwPuCCqvp6dyVKkoYxcISeJMC1wKGqunqFNpuA7cDFVfX5bkuUJA1jmBH6OcDFwIEk+/v3XQlsAqiqa4A3AacD7+nlP0eqar77ciVJKxlmlcst9NaXH6/Na4DXdFWUJGn13PovSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGg6xie1SnNJg+40MN4Vqc0uxyh62EmcZycpG4Y6HoYz+qUZpdTLnoYz+qUZpeBrmN4nJw0m5xy6YCrQiRNA0foJ8hVIZKmhSP0E+SqEEnTwkA/Qa4KkTQtnHI5Qa4KkTQtDPQOuCpE0jRwykWSGmGgD8mliZKmnVMuQ3BpoqRZ4Ah9CC5NlDQLDPQhuDRR0ixwymUILk2UNAsM9CG5NFHStHPKRZIaYaBLUiMMdElqhIEuSY0w0CWpEQMDPcnGJDclOZjkjiRvWKZNkrwzyZ1Jbkvy7NGUK0layTDLFo8Al1fVviTrgb1Jbqyqg4vaXAA8rf/xXOC9/c+SpDEZOEKvqsNVta9/+wHgELBhSbOLgOuq51bgtCRP7LxaSdKKVjWHnmQzsAXYveShDcBXFn19N8eGPkm2JtmTZM/CwsLqKpUkHdfQgZ7kVOAG4LKquv+RvFhVbauq+aqan5ubeyRPIUlawVCBnmQdvTC/vqq2L9Pkq8DGRV+f2b+vc16XXJKWN/BN0SQBrgUOVdXVKzTbAfxOkg/RezP0vqo63F2ZPV6XXJJWNswql3OAi4EDSfb377sS2ARQVdcAfw9cCNwJfBt4dfelLn9dcgNdknoGBnpV3QJkQJsCXtdVUSs5el3yoyN0r0suST8wU5fP9brkkrSymQp08LrkkrQSr+UiSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGpHenqAJvHCyAHx5ld92BnDvCMqZdvZ7bVmr/Ya12/fV9PtJVbXs1Q0nFuiPRJI9VTU/6TrGzX6vLWu137B2+95Vv51ykaRGGOiS1IhZC/Rtky5gQuz32rJW+w1rt++d9Hum5tAlSSubtRG6JGkFBrokNWIqAz3J+Uk+l+TOJL+3zOOPTvLh/uO7k2wef5XdG6Lfv5vkYJLbknwyyZMmUWfXBvV7UbtfTlJJmljWNky/k/xq/2d+R5K/HHeNozDE7/mmJDcl+Uz/d/3CSdTZtSR/luSeJLev8HiSvLP/3+W2JM9e9YtU1VR9ACcB/wU8BTgF+Czw9CVtfhu4pn/75cCHJ133mPr9AuCH+7dfu1b63W+3HrgZuBWYn3TdY/p5Pw34DPAj/a8fP+m6x9TvbcBr+7efDnxp0nV31PefBZ4N3L7C4xcCn6B3QtzzgN2rfY1pHKH/DHBnVX2hqh4EPgRctKTNRcAH+rc/CpzXP8x6lg3sd1XdVFXf7n95K3DmmGschWF+3gBvAd4KfGecxY3QMP3+LeDdVfVNgKq6Z8w1jsIw/S7gsf3bjwO+Nsb6Rqaqbga+cZwmFwHXVc+twGlJnria15jGQN8AfGXR13f371u2TVUdAe4DTh9LdaMzTL8Xu4Tev+azbmC/+396bqyqvxtnYSM2zM/7LOCsJJ9OcmuS88dW3egM0+8/BF6R5G56B9C/fjylTdxqM+AYM3cEnSDJK4B54PmTrmXUkjwKuBp41YRLmYST6U27nEvvr7Gbk/xkVX1rolWN3q8B76+qP05yNvDBJM+oqocmXdi0m8YR+leBjYu+PrN/37JtkpxM78+yr4+lutEZpt8k+TngjcBLquq7Y6ptlAb1ez3wDGBnki/Rm1vc0cAbo8P8vO8GdlTV96rqi8Dn6QX8LBum35cAHwGoql3AY+hdvKp1Q2XA8UxjoP8H8LQkT05yCr03PXcsabMDeGX/9kuBT1X/XYUZNrDfSbYAf0ovzFuYT4UB/a6q+6rqjKraXFWb6b138JKq2jOZcjszzO/5x+iNzklyBr0pmC+Ms8gRGKbfdwHnAST5CXqBvjDWKidjB/Cb/dUuzwPuq6rDq3qGSb/ze5x3ez9P793wN/bvezO9/5Gh9wP+a+BO4N+Bp0y65jH1+5+B/wb29z92TLrmcfR7SdudNLDKZcifd+hNNx0EDgAvn3TNY+r304FP01sBsx940aRr7qjffwUcBr5H76+vS4BLgUsX/bzf3f/vcuCR/J679V+SGjGNUy6SpEfAQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmN+D9HSzMV0NW+8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hld6OtzLUUQ"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnuJmjOSLUUQ"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkccEZvFLUUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06163a0c-6de9-4051-c314-e8dbbd11daa3"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(LinearLayer, self).__init__()\n",
        "    self.m = self.add_weight(shape=(1,),\n",
        "                             initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(1,),\n",
        "                             initializer='zeros')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return self.m*inputs+self.b\n",
        "\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.06933199 0.023721   0.07912418 0.03079096 0.04425802 0.01021458\n",
            " 0.04513784 0.0005613  0.06225901 0.06271388 0.00839703 0.03471534\n",
            " 0.02714759 0.06329098 0.08046802 0.05948634 0.03361373 0.01292873\n",
            " 0.05710317 0.05492993], shape=(20,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.08147576], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15edBCaOLUUR"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k-DUU6gLUUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595753c8-6cfa-41ff-967c-39182a513437"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.1552916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78PCHSggLUUS"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsyh04g5LUUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bfd9e9-f761-4a81-d59d-a089cb470b5c"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = linear_regression(x_train)\n",
        "    loss = SquaredError(predictions, y_train)\n",
        "\n",
        "  gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "  linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
        "  linear_regression.b.assign_sub(learning_rate * gradients[0])\n",
        "\n",
        "  print(\"Step %d, Loss %f\" % (i, loss.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 6.155292\n",
            "Step 1, Loss 5.140264\n",
            "Step 2, Loss 4.295762\n",
            "Step 3, Loss 3.592967\n",
            "Step 4, Loss 3.007949\n",
            "Step 5, Loss 2.520832\n",
            "Step 6, Loss 2.115104\n",
            "Step 7, Loss 1.777052\n",
            "Step 8, Loss 1.495284\n",
            "Step 9, Loss 1.260334\n",
            "Step 10, Loss 1.064337\n",
            "Step 11, Loss 0.900758\n",
            "Step 12, Loss 0.764163\n",
            "Step 13, Loss 0.650038\n",
            "Step 14, Loss 0.554628\n",
            "Step 15, Loss 0.474813\n",
            "Step 16, Loss 0.407995\n",
            "Step 17, Loss 0.352016\n",
            "Step 18, Loss 0.305078\n",
            "Step 19, Loss 0.265688\n",
            "Step 20, Loss 0.232598\n",
            "Step 21, Loss 0.204775\n",
            "Step 22, Loss 0.181353\n",
            "Step 23, Loss 0.161614\n",
            "Step 24, Loss 0.144958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i3p09LQLUUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d79c221d-bf7e-4d5a-9af0-f66987a17923"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[1.4811265]\n",
            "b:2,  trained b:[1.3996508]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f06ebf43fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G5NMaI6LUUV"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvcprQYVLUUW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvowknegLUUW"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T51Wq6QLUUW"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMjThE3yLUUW"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.units = units  # number of layer units (weights)\n",
        "\n",
        "  # add build method to the MyLayer class to avoid setting the input shape until the layer is called (flexible shapes)\n",
        "  # name the layer parts for simplify usage\n",
        "  def build(self, input_shape):\n",
        "    # layer weights\n",
        "    self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                             initializer='random_normal',\n",
        "                             name='kernel')\n",
        "    # layer bias\n",
        "    self.b = self.add_weight(shape=(self.units,),\n",
        "                             initializer='zeros',\n",
        "                             name='bias')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)  # call activations here, otherwise the layers will be linear\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96UhxxnmSAQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae16fb63-3bbb-44b9-9f4c-5bbf7078b139"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()  # is the exact same as above"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.02469273 0.02422069 0.02116902 0.03153074 0.04185418 0.02650914\n",
            "  0.02331334 0.01793654 0.01791891 0.01802885 0.02326367 0.02021981\n",
            "  0.01426613 0.02719969 0.0274377  0.01693712 0.01283608 0.01822274\n",
            "  0.02904254 0.02264908 0.02145478 0.0146747  0.01371288 0.02708716\n",
            "  0.02050998 0.02386188 0.01340397 0.0286968  0.02174951 0.02303861\n",
            "  0.01563685 0.02124431 0.02675487 0.0135526  0.03268624 0.0201091\n",
            "  0.02344291 0.02400806 0.01627981 0.01386968 0.02272227 0.0246389\n",
            "  0.0211106  0.02249501 0.01746694 0.01654291]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_16 (MyLayer)        multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_10 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_17 (MyLayer)        multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_11 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_18 (MyLayer)        multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_5 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVeAi3oLUUX"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crNKTJcWLUUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d343758b-ba9f-4df7-b473-fd7b4b405099"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_nw7MGBLUUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2217ba5-0299-4bde-edb6-ee9a42f8b00e"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbCx1JBzLUUY"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbg5RxiULUUY"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HCGngsKLUUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c1578e-9a8e-4e56-e1e8-65a3c415b0af"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "print(text_news)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f1vpdH3LUUa"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQGQvdroLUUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ca3a6f-8f74-451f-84b4-ab7cb392f175"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbO8liN6LUUa"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52aLcCVjLUUb"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    # weight decay penalty as regulizer\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTI9s3uLUUb"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl5cnYrULUUb"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xZ6JAHWLUUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0196a7ef-3997-4dec-f4f2-ab9934c65d25"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_avg_loss = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  # training loop\n",
        "  for x, y in train_dataset:\n",
        "    # optimize model\n",
        "    loss_value, grads = grad(model, x, y, weight_decay)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    # compute current loss\n",
        "    epoch_avg_loss(loss_value)\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "  # end epoch\n",
        "  train_loss_results.append(epoch_avg_loss.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch, epoch_avg_loss.result(), epoch_accuracy.result()))\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: Loss: 3.318, Accuracy: 47.996%\n",
            "Epoch 001: Loss: 1.934, Accuracy: 59.575%\n",
            "Epoch 002: Loss: 1.839, Accuracy: 65.153%\n",
            "Epoch 003: Loss: 1.792, Accuracy: 68.203%\n",
            "Epoch 004: Loss: 1.756, Accuracy: 69.016%\n",
            "Epoch 005: Loss: 1.749, Accuracy: 69.773%\n",
            "Epoch 006: Loss: 1.724, Accuracy: 70.252%\n",
            "Epoch 007: Loss: 1.716, Accuracy: 70.296%\n",
            "Epoch 008: Loss: 1.700, Accuracy: 70.842%\n",
            "Epoch 009: Loss: 1.705, Accuracy: 70.875%\n",
            "Duration :94.792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXndbryiLUUc"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t7q07X4LUUd"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tzyWahXLUUd"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoGdLJxvLUUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb92c9aa-5d9e-46b6-c6f1-30b16a861bee"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.840\n",
            "Test accuracy: 67.720%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEynBdgSLUUe"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuNWatmCLUUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "4721541a-44d7-4c9a-fe6d-b2ecefe1ce1e"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb01fQDdLUUe"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MCG0AcSLUUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8fea26-3826-4155-be2c-e4376f89e184"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: earn\n",
            "     Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxYi1O0eLUUf"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1qRUx4pLUUf"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7tIhJlmLUUf"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKjsmSeFLUUf",
        "outputId": "6215b40c-2e7d-44ce-e4d3-c7da9e0c87db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initialize a new model\n",
        "\n",
        "model = MyModel(64,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()  # is the exact same as above"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.0157793  0.01995642 0.01371924 0.00754535 0.02380487 0.02748704\n",
            "  0.06976582 0.00746593 0.00269733 0.00413884 0.00738348 0.00837831\n",
            "  0.00287195 0.01909052 0.01206377 0.02009192 0.01970806 0.00673163\n",
            "  0.00998205 0.02283304 0.05091274 0.01791169 0.00705515 0.02257455\n",
            "  0.00492392 0.01206135 0.11640094 0.00563481 0.03504296 0.00844257\n",
            "  0.01600087 0.00273831 0.00950017 0.02514022 0.0172752  0.02607905\n",
            "  0.01926632 0.09308005 0.04465098 0.01275241 0.00660244 0.0181314\n",
            "  0.0119268  0.08133545 0.00903711 0.00402766]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_19 (MyLayer)        multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_12 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_20 (MyLayer)        multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_13 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_21 (MyLayer)        multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_6 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chCMaQVHLUUg"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SFxLecjLUUg"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n",
        "@tf.function\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ihrPhcgLUUg"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWAygEjxLUUg",
        "outputId": "f12774be-4b74-4f80-e512-a48388f6fecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Re-run the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_avg_loss = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  # training loop\n",
        "  for x, y in train_dataset:\n",
        "    # optimize model\n",
        "    loss_value, grads = grad(model, x, y, weight_decay)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    # compute current loss\n",
        "    epoch_avg_loss(loss_value)\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "  # end epoch\n",
        "  train_loss_results.append(epoch_avg_loss.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch, epoch_avg_loss.result(), epoch_accuracy.result()))\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: Loss: 2.436, Accuracy: 57.059%\n",
            "Epoch 001: Loss: 1.915, Accuracy: 65.264%\n",
            "Epoch 002: Loss: 1.843, Accuracy: 67.624%\n",
            "Epoch 003: Loss: 1.782, Accuracy: 68.314%\n",
            "Epoch 004: Loss: 1.775, Accuracy: 68.904%\n",
            "Epoch 005: Loss: 1.747, Accuracy: 69.183%\n",
            "Epoch 006: Loss: 1.722, Accuracy: 70.018%\n",
            "Epoch 007: Loss: 1.721, Accuracy: 70.341%\n",
            "Epoch 008: Loss: 1.707, Accuracy: 70.040%\n",
            "Epoch 009: Loss: 1.712, Accuracy: 70.430%\n",
            "Duration :79.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2ksbrg0LUUh"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saVdQgvWLUUh",
        "outputId": "cb24a71d-1718-46f9-e0ea-d8d244fd0a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__grad(model, inputs, targets, wd):\n",
            "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        with ag__.ld(tf).GradientTape() as tape:\n",
            "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}